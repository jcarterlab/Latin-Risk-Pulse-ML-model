{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d8d24c-028b-49a8-b021-423d55031ae1",
   "metadata": {},
   "source": [
    "# 7) Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdb33c-1d55-47c3-9ee5-cc8e14339ab0",
   "metadata": {},
   "source": [
    "Tuning the support vector machine model shows..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ec932-b36f-4052-9865-7d4c7fb79ec6",
   "metadata": {},
   "source": [
    "## Read-in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0b1ce-7c9a-4c6f-9511-b6e3b908e496",
   "metadata": {},
   "source": [
    "Seperate dataframes are read-in for each language and dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386c8da7-6969-404d-9fa0-c02490c24e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.3K Spanish train headlines\n",
      "0.6K Spanish put aside headlines\n",
      "6.6K Portuguese train headlines\n",
      "0.6K Portuguese put aside headlines\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# reads in the spanish improved label headlines\n",
    "spanish_improved_labels_df = pd.read_csv('../Data/spanish_improved_labels_df.csv', encoding='utf-8').reset_index(drop=True)\n",
    "print(str(round(len(spanish_improved_labels_df)/1000, 1)) + 'K Spanish train headlines')\n",
    "\n",
    "# reads in the spanish put aside headlines\n",
    "spanish_put_aside_df = pd.read_csv('../Data/spanish_put_aside_df.csv', encoding='utf-8').reset_index(drop=True)\n",
    "print(str(round(len(spanish_put_aside_df)/1000, 1)) + 'K Spanish put aside headlines')\n",
    "\n",
    "# reads in the portuguese improved label headlines\n",
    "portuguese_improved_labels_df = pd.read_csv('../Data/portuguese_improved_labels_df.csv', encoding='utf-8').reset_index(drop=True)\n",
    "print(str(round(len(portuguese_improved_labels_df)/1000, 1)) + 'K Portuguese train headlines')\n",
    "\n",
    "# reads in the portuguese put aside headlines\n",
    "portuguese_put_aside_df = pd.read_csv('../Data/portuguese_put_aside_df.csv', encoding='utf-8').reset_index(drop=True)\n",
    "print(str(round(len(portuguese_put_aside_df)/1000, 1)) + 'K Portuguese put aside headlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083abac-b485-4f66-b648-17dc6b7a1998",
   "metadata": {},
   "source": [
    "## Create risk type dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f8c72-b6f9-4539-8f8c-72ef573f4fa6",
   "metadata": {},
   "source": [
    "Creates a dataframe with all the headlines from a certain risk type and an equal number of other headlines. These other headlines include both non-risk type headlines and other risk types, helping the model to learn better by distinguishing between specific risk types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585e63db-2c23-45e2-8836-f4d0effaa80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# returns a dataframe containing all of a specific risk type and and equal number \n",
    "# of randomly sampled other and non risks\n",
    "def risk_type_df(df, risk_type):\n",
    "    # a specified risk type \n",
    "    risk_type_df = df.loc[df.risk_type==risk_type]\n",
    "\n",
    "    # ranodmly sampled non risks\n",
    "    population, sample_no = list(df.loc[~df.index.isin(risk_type_df.index)].index), len(risk_type_df)\n",
    "    non_risks = random.sample(population, sample_no)\n",
    "    non_risks_df = df.loc[df.index.isin(non_risks)]\n",
    "\n",
    "    # concatenates risks and non-risks\n",
    "    risk_type_df = pd.concat([risk_type_df, non_risks_df])\n",
    "\n",
    "    # creates a binary coolumn to indicate whether a risk is the specified risk type or not\n",
    "    risk_type_df['y_value'] = [1 if x == risk_type else 0 for x in risk_type_df['risk_type']]\n",
    "    \n",
    "    return risk_type_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bdf8fb-9f3a-4eda-9db9-982b2febfe40",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f69f8-5238-4d8d-98d2-b7f3e8f4ab3d",
   "metadata": {},
   "source": [
    "A model is fit and evaluated on TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4289675c-eb44-47de-83c0-a5ad60d0306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# returns a train test split\n",
    "def split_data(df, risk_type, test_size=0.25):\n",
    "    # defines X\n",
    "    X = df.headline\n",
    "    \n",
    "    # defines y\n",
    "    if risk_type != None:\n",
    "        y = df.y_value\n",
    "    else:\n",
    "        y = [int(pd.notna(x)) for x in df.risk_type]\n",
    "        \n",
    "    # returns a split\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=y)\n",
    "\n",
    "# evaluates a model by printing the accuracy and classification report\n",
    "def evaluate_model(model, X_test_tfidf, y_test):\n",
    "    # generates predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 2))\n",
    "    print()\n",
    "    \n",
    "    # prints classification report\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    return classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# evaluates a filtered dataset against new headlines using tf-idf vectors and logistic regression \n",
    "def fit_evaluate_tfidf(model, train_df, put_aside_df, risk_type, language):\n",
    "    # prints the language\n",
    "    print()\n",
    "    print('*** ' + language + ': ' + str(risk_type) + ' ***')\n",
    "    print()\n",
    "\n",
    "    # reassigns the train df to focus on a particular risk type and defines the y_test variable\n",
    "    if risk_type != None:\n",
    "        train_df, y_test = risk_type_df(train_df, risk_type), [1 if x == risk_type else 0 for x in put_aside_df['risk_type']]\n",
    "    else:\n",
    "        y_test = [int(pd.notna(x)) for x in put_aside_df.risk_type]\n",
    "        \n",
    "    # instantiate vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # prepare data\n",
    "    X_train, X_test, y_train, NOT_Y_TEST = split_data(train_df, risk_type, test_size=0.001)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(put_aside_df.headline)\n",
    "\n",
    "    # fit logistic regression model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # evaluate data\n",
    "    print(str(len(put_aside_df)) + ' put aside headlines')\n",
    "    return evaluate_model(model, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587943ca-f48d-4aaa-9b51-bbaf93cbe553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4fb205-5990-47c2-ba7b-1b16504f7df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7891cb84-5f93-4bc8-ab5a-f8cfecf56a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the risk type\n",
    "risk_type = 'political_stability'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0310a-97bf-4130-93a1-296ab5cee6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8b719-dde4-4458-8fc2-592ce4b2bb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b2a5f-dc6d-4a91-be6c-0256c8d73af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b158d-5585-4ea7-b0bb-a2dcb750bfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae5f73-f46a-4ca1-bfbf-23f96e71e2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266acd28-1b59-4549-b003-950d94c8db1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221b820-e0cf-4da6-a762-aeb6bfd80a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decb81d-0e85-485c-8511-822d024a4a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c690265-665f-439e-8ac6-2600c5267e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7b24e-fed3-40ff-a332-b6d11046a5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a458055-05db-4225-bfb1-a8b0859da103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80458227-98c6-4f8b-b24a-d91f41ff7dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
