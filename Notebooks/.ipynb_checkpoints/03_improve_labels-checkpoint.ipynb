{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0583d6-ce4f-4a6b-90e2-b5c491bab49c",
   "metadata": {},
   "source": [
    "# 03) Improve labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179755f3-9933-450c-85c2-3f3462b80b51",
   "metadata": {},
   "source": [
    "A key problem with the headlines data is that the keyword matching process during data collection likely missed many non-risk headlines, meaning the dataset liekly contains mislabelled data. To tackle this problem, a regression model for each language (Spanish and Portuguese) is trained on half of the data at a time to generate predictions for the other half's headlines. A percentage of headlines at a certain probability score from each half is kept, helping to eliminate many false negatives and tackling the class imbalance problem (see notebook 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df94d6-83db-4396-8697-9615ce4ebf8a",
   "metadata": {},
   "source": [
    "## Read-in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616ac5e-0973-4b72-8a57-4765133e4f53",
   "metadata": {},
   "source": [
    "Seperate dataframes are created for each language (Spanish & Portuguese). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a81d4ae-639e-4e61-802b-7b339ca3a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.2K Total headlines\n",
      "77.3K Spanish headlines\n",
      "15.2K Portuguese headlines\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read-in data\n",
    "df = pd.read_csv('../Data/original_headlines.csv', encoding='utf-8')\n",
    "print(str(round(len(df)/1000, 1)) + 'K Total headlines')\n",
    "\n",
    "# include only spanish \n",
    "spanish_df = df[df.country.isin(['Argentina', 'Colombia', 'Mexico'])].reset_index(drop=True)\n",
    "print(str(round(len(spanish_df)/1000, 1)) + 'K Spanish headlines')\n",
    "\n",
    "# include only portuguese \n",
    "portuguese_df = df[df.country == 'Brazil'].reset_index(drop=True)\n",
    "print(str(round(len(portuguese_df)/1000, 1)) + 'K Portuguese headlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fed9ac-09c7-41ca-bfe2-fc5cb3364ec0",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb259b58-b2bb-41d5-9e8f-16cd6daffba4",
   "metadata": {},
   "source": [
    "### Remove duplicates & thumbnails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a3559-f4ba-47aa-9288-51ce2f79e452",
   "metadata": {},
   "source": [
    "Headlines containing the word thumbnail are normally videos which cannot be scraped. Many of these with a similar format in the non-risk headlines data add little value in terms of variety and therefore are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa294472-f20c-4ad3-bc71-c140c9036403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "spanish_df.drop_duplicates(subset='headline', inplace=True)\n",
    "portuguese_df.drop_duplicates(subset='headline', inplace=True)\n",
    "\n",
    "# remove thumbnails\n",
    "spanish_df = spanish_df[~spanish_df['headline'].str.lower().str.contains('thumbnail', na=False)]\n",
    "portuguese_df = portuguese_df[~portuguese_df['headline'].str.lower().str.contains('thumbnail', na=False)]\n",
    "\n",
    "# removes english headlines from the spanish dataset\n",
    "spanish_df = spanish_df.loc[~spanish_df.website.isin(['Colombia Reports'])]\n",
    "\n",
    "# reset index\n",
    "spanish_df.reset_index(drop=True, inplace=True)\n",
    "portuguese_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a4cfdf-febc-45df-9704-eb429daa4e94",
   "metadata": {},
   "source": [
    "### Clean headline text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77409c-89c6-455f-89cd-60c73b8cd091",
   "metadata": {},
   "source": [
    "The text is subjected to common cleaning techniques to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2156dd2c-0fd0-40f3-b6b4-078b8235a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jack-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "spanish_stop_words = set(stopwords.words('Spanish'))\n",
    "portuguese_stop_words = set(stopwords.words('Portuguese'))\n",
    "\n",
    "# common text cleaning techniques\n",
    "def clean_text(text, language):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + '¡¿'))\n",
    "\n",
    "    if language=='Spanish':\n",
    "        text = ' '.join([word for word in text.split() if word not in spanish_stop_words])\n",
    "    elif language=='Portuguese':\n",
    "        text = ' '.join([word for word in text.split() if word not in portuguese_stop_words])\n",
    "    \n",
    "    return text\n",
    "\n",
    "spanish_df['headline'] = [clean_text(x, 'Spanish') for x in spanish_df['headline']]\n",
    "portuguese_df['headline'] = [clean_text(x, 'Portuguese') for x in portuguese_df['headline']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d40aa8-3ec9-4f72-9df0-b43df77b2e83",
   "metadata": {},
   "source": [
    "## Put aside data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6d8f0-8a8d-45bb-b234-dcda29e3c4c2",
   "metadata": {},
   "source": [
    "### Split datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839b17f-75ef-4dc8-851f-87ea9cda453a",
   "metadata": {},
   "source": [
    "A percentage of the data from each dataframe is put aside. This is useful to make sure we don't end up evaluating on an artificially easy dataset in which most of the more difficult edge cases for non-risk headlines have been removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b46b6d-e836-42cc-8220-0d5699ff9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# returns the main dataframe and a random sample to be put aside for evaluation\n",
    "def put_aside_random_percent(df, percent):\n",
    "    indices = list(df.index)\n",
    "    dividor = int(100 / percent)\n",
    "    sample_size = int(np.floor(len(indices)/dividor))\n",
    "    random_sample = random.sample(indices, sample_size)\n",
    "    put_aside_headlines = df.iloc[random_sample,:].reset_index(drop=True)\n",
    "    df = df.loc[~df.index.isin(random_sample)].reset_index(drop=True)\n",
    "    return df, put_aside_headlines\n",
    "\n",
    "spanish_df_post_sample, raw_spanish_put_aside_df = put_aside_random_percent(spanish_df, 10)\n",
    "portuguese_df_post_sample, raw_portuguese_put_aside_df = put_aside_random_percent(portuguese_df, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c4fa8-7ae0-4cd1-bc20-bb2078e06b5e",
   "metadata": {},
   "source": [
    "### Curate put aside df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b147d-7531-42e8-99d1-87abeb70047a",
   "metadata": {},
   "source": [
    "The put aside dataframe is filtered to include only keyword matches. While this drastically reduces the non-risk headlines, it also reduces the risk of evaluating on mislabeled data (due to risk headlines that were not keyword matched). It also means we are evaluating on a dataset that includes many of the more difficult non-risk edge cases and not an artificially easy one in which many of them have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675d7ec6-cc11-4f30-aec4-3f900c875f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Spanish ***\n",
      "\n",
      "non-risks: 464\n",
      "risks: 977\n",
      "\n",
      "*** Portuguese ***\n",
      "\n",
      "non-risks: 224\n",
      "risks: 339\n"
     ]
    }
   ],
   "source": [
    "def filter_put_aside_df(df, title):\n",
    "    print()\n",
    "    print('*** ' + title + ' ***')\n",
    "    print()\n",
    "    keyword_hits = df.loc[~pd.isna(df.keyword_hit)]\n",
    "    non_risks = keyword_hits.loc[pd.isna(keyword_hits.risk_type)]\n",
    "    risks = keyword_hits.loc[~pd.isna(keyword_hits.risk_type)]\n",
    "    print('non-risks: ' + str(len(non_risks)))\n",
    "    print('risks: ' + str(len(risks)))\n",
    "    return pd.concat([risks, non_risks])\n",
    "\n",
    "spanish_put_aside_df = filter_put_aside_df(raw_spanish_put_aside_df, 'Spanish')\n",
    "portuguese_put_aside_df = filter_put_aside_df(raw_portuguese_put_aside_df, 'Portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bb365-106a-464d-8a44-68c3e6c5d261",
   "metadata": {},
   "source": [
    "## Improve label quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde4337-0ee8-441c-ad72-c0a22eff56f6",
   "metadata": {},
   "source": [
    "### Split dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad3760-0778-4cd1-a8d4-56e4afc09132",
   "metadata": {},
   "source": [
    "Each dataframe is randomly split into two sets so a model can be trained on each set and used to predict headlines for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac502d8e-2ee1-4945-adbb-08f875793708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split a dataframe into 2 equal size groups \n",
    "def split_dataframes(df):\n",
    "    population = list(range(len(df)))\n",
    "    half_headlines = int(np.floor(len(population) / 2))\n",
    "    random_samples = random.sample(population, half_headlines)\n",
    "    return df.loc[random_samples,:].reset_index(drop=True), df.loc[~df.index.isin(random_samples), :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ab7a5-0013-4c5a-9211-43c3a4740fbb",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83f72d-10e8-4d8c-ad4c-2ac7036bec22",
   "metadata": {},
   "source": [
    "A model is fit using TF-IDF vectors and logistic regression. A regression model is used to obtain probabilities so that the classification threshold can be easily varied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a650657-5a11-4fa9-81cb-8563d834430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# vectorizes data and fits a model \n",
    "def fit_model(df):\n",
    "    X, y = df.headline, [int(pd.notna(x)) for x in df.risk_type]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    train_tfidf = vectorizer.fit_transform(X)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_tfidf, y)\n",
    "    return vectorizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab4d7d-7f58-4536-acd3-c63e974f3da4",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ed46e-0ff1-4bb7-83fd-c11e7810b208",
   "metadata": {},
   "source": [
    "Predictions from one half of each dataset are added to the other half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962ca39-2012-4ba9-8924-249aa61d0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns predictions as binary decisions and probabilities\n",
    "def predict_headlines(df, vectorizer, model):\n",
    "    tfidf_vectors = vectorizer.transform(df.headline)\n",
    "    y_preds = model.predict(tfidf_vectors)\n",
    "    y_pred_prob = [np.mean(model.predict_proba(x)[:, 1]) for x in tfidf_vectors]\n",
    "    return y_preds, y_pred_prob \n",
    "\n",
    "# adds the predictions for each half of the data to their respective dfs\n",
    "def add_predictions_to_df(primary_df, secondary_df):\n",
    "    vectorizer, model = fit_model(secondary_df)\n",
    "    y_preds, y_pred_prob = predict_headlines(primary_df, vectorizer, model)\n",
    "    primary_df['y_pred'], primary_df['y_pred_prob'] = y_preds, y_pred_prob\n",
    "    primary_df.sort_values('y_pred_prob', ascending=False, inplace=True)\n",
    "    return primary_df\n",
    "\n",
    "# returns a headlines dataframe along with their predictions for veiwing\n",
    "# this is useful so we can set appropriate upper and lower limits for the \n",
    "# slice of low probability non-risk headlines we will select later on\n",
    "def return_headline_preds(df, language):\n",
    "    df_1, df_2 = split_dataframes(df) \n",
    "    df_1, df_2 = add_predictions_to_df(df_1, df_2), add_predictions_to_df(df_2, df_1)\n",
    "    #df_1, df_2 =  drop_non_risk_headlines(df_1, language), drop_non_risk_headlines(df_2, language)\n",
    "    return df_1, df_2\n",
    "\n",
    "spanish_df_1, spanish_df_2 = return_headline_preds(spanish_df_post_sample, 'Spanish')\n",
    "portuguese_df_1, portuguese_df_2 = return_headline_preds(portuguese_df_post_sample, 'Portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a16e5-01d9-4381-82f2-e8cbbf17f617",
   "metadata": {},
   "source": [
    "### Find false negatives threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8efb4-5613-4d93-be69-ebc2e01951a7",
   "metadata": {},
   "source": [
    "The threshold at which false negatives are no longer common is located and used for the upper limits in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34fd48-344e-48e3-bdb8-7a9f97de61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function shows the non-risk labelled headlines ordered\n",
    "# from the lowest to highest probability score. An ml practitioner \n",
    "# can use this to find the appropriate threshold for which \n",
    "# there are no longer many false negatives in the data...\n",
    "def view_nonrisk_highest_rows(df, start, end):\n",
    "    temp_df = df.loc[pd.isna(df.risk_type)].sort_values('y_pred_prob')\n",
    "    print()\n",
    "    print('Non-risk headlines: ' + str(len(temp_df)))\n",
    "    print()\n",
    "    selected_index_df = temp_df.iloc[start:end, :]\n",
    "    for i in range(len(selected_index_df)):\n",
    "        print(str(selected_index_df.index[i]) + ':   ' + selected_index_df.headline.values[i])\n",
    "    percent = end / len(temp_df)\n",
    "    return percent\n",
    "\n",
    "spanish_false_negative_percent = view_nonrisk_highest_rows(spanish_df_1, 7990, 8000)\n",
    "portuguese_false_negative_percent = view_nonrisk_highest_rows(portuguese_df_1, 1990, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa88004-8879-4db2-b99e-1e532e355adf",
   "metadata": {},
   "source": [
    "### Drop false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9044d4-137d-4f8a-a3e7-78340defc58c",
   "metadata": {},
   "source": [
    "All non-risk headlines above the threshold above are dropped, eliminating many false negatives and tackling the class imbalance problem (see notebook 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f024a71-a4b9-4064-a061-10fea3991bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops a number of non-risk headlines based on their prediction scores\n",
    "def drop_non_risk_headlines(df, percent):   \n",
    "    non_risk_df = df.loc[pd.isna(df.risk_type)]\n",
    "    risk_df = df.loc[~pd.isna(df.risk_type)]\n",
    "    lower_limit, upper_limit = 0, int(np.floor(len(non_risk_df) * percent))\n",
    "    low_score_non_risk = non_risk_df.iloc[(len(non_risk_df)-upper_limit):(len(non_risk_df)-lower_limit),:]\n",
    "    return pd.concat([risk_df, low_score_non_risk])\n",
    "\n",
    "# creates a filtered dataframe combining both halfs of the data \n",
    "# after dropping headlines with high predictions\n",
    "def create_filtered_df(df_1, df_2, percent):\n",
    "    df_1, df_2 =  drop_non_risk_headlines(df_1, percent), drop_non_risk_headlines(df_2, percent)\n",
    "    return pd.concat([df_1, df_2])\n",
    "\n",
    "false_negatives_filtered_spanish_df = create_filtered_df(spanish_df_1, spanish_df_2, spanish_false_negative_percent)\n",
    "false_negatives_filtered_portuguese_df = create_filtered_df(portuguese_df_1, portuguese_df_2, portuguese_false_negative_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198fb858-ea54-4e01-a4b1-0b5e5efe3869",
   "metadata": {},
   "source": [
    "### Find false positives threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d2e7c-357c-4be8-81f8-5894bc43ef2e",
   "metadata": {},
   "source": [
    "The threshold for false positives is found by exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0108055-5cf3-4291-845b-8f752b582bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function shows the risk labelled headlines ordered\n",
    "# from the lowest to highest probability score. An ml practitioner \n",
    "# can use this to find the appropriate threshold for which \n",
    "# there are no longer many false positives in the data...\n",
    "def view_risk_lowest_rows(df, start, end):\n",
    "    temp_df = df.loc[~pd.isna(df.risk_type)].sort_values('y_pred_prob').reset_index(drop=True)\n",
    "    print()\n",
    "    print('Risk headlines: ' + str(len(temp_df)))\n",
    "    print()\n",
    "    selected_index_df = temp_df.iloc[start:end, :]\n",
    "    for i in range(len(selected_index_df)):\n",
    "        print(str(selected_index_df.index[i]) + ':   ' + selected_index_df.headline.values[i])\n",
    "    percent = end / len(temp_df)\n",
    "    return percent\n",
    "    \n",
    "spanish_false_positive_percent = view_risk_lowest_rows(false_negatives_filtered_spanish_df, 50, 60)\n",
    "portuguese_false_positive_percent = view_risk_lowest_rows(false_negatives_filtered_portuguese_df, 30, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90abb17-5134-4c48-b36a-549087425626",
   "metadata": {},
   "source": [
    "### Drop false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b14cc-9d76-4355-a4ad-e3710de975a9",
   "metadata": {},
   "source": [
    "Many false posiitves are dropped from the data based on their percentage ranking when ordered by their y preds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99308d1e-8f7e-414e-a434-7e02cc659960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops a number of risk headlines based on their prediction scores\n",
    "def drop_risk_headlines(df, percent):   \n",
    "    risk_df = df.loc[~pd.isna(df.risk_type)].sort_values('y_pred_prob')\n",
    "    non_risk_df = df.loc[pd.isna(df.risk_type)]\n",
    "    lower_limit, upper_limit = 0, int(np.floor(len(risk_df) * percent))\n",
    "    high_score_risk = risk_df.iloc[upper_limit:len(risk_df),:]\n",
    "    combined_df = pd.concat([high_score_risk, non_risk_df])\n",
    "    return combined_df.reset_index(drop=True)\n",
    "\n",
    "false_positives_filtered_spanish_df = drop_risk_headlines(false_negatives_filtered_spanish_df, spanish_false_positive_percent)\n",
    "false_positives_filtered_portuguese_df = drop_risk_headlines(false_negatives_filtered_portuguese_df, portuguese_false_positive_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f1d00-bfd5-4a0c-9d8a-671d2c8d532a",
   "metadata": {},
   "source": [
    "## Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7736f3-fa01-494f-97b0-c56ae9bf9e9b",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef542219-483e-4df0-b305-1795bce8e170",
   "metadata": {},
   "source": [
    "Creates a train test split for a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ae042-787f-4062-a379-53c4c7965c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# returns a train test split\n",
    "def split_data(df, test_size=0.25):\n",
    "    X = df.headline\n",
    "    y = [int(pd.notna(x)) for x in df.risk_type]\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb49fe-5010-4b12-bd75-c8ba47173e18",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ea452-06c4-4599-b55f-5f3848fba6c5",
   "metadata": {},
   "source": [
    "Prints the accuracy and classification report for a given model on a given set of headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738b006-d7ac-46ce-b84d-659a6fdae24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# evaluates the model's performance and prints the results\n",
    "def evaluate_model(model, X_test_tfidf, y_test):\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    y_pred_prob = model.predict_proba(X_test_tfidf)[:, 1] \n",
    "    classification_report_ = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy:\", round(accuracy_score(y_test, y_pred),3))\n",
    "    print(\"Classification Report:\\n\", classification_report_)\n",
    "    print()\n",
    "    return classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2774c43-ef02-4c6d-970e-f1abfaf243fc",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77f701-1521-46cb-856f-0dfe1abfa4bd",
   "metadata": {},
   "source": [
    "A model is trained on the filtered dataset and evaluated on the set aside data. As we can see, the recall for risk headlines (the main business objective of this project) has improved dramatically for both languages (see notebook 2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5cfb4-7b65-44e0-bafe-fc1e01327d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates a filtered dataset against new headlines\n",
    "def check_results(train_df, put_aside_df, language):\n",
    "    print()\n",
    "    print('*** ' + language + ' ***')\n",
    "    print()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(train_df, test_size=0.01)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    print(str(round(len(put_aside_df)/1000, 2)) + 'K put aside headlines')\n",
    "    \n",
    "    X_test_tfidf = vectorizer.transform(put_aside_df.headline)\n",
    "    y_test = [int(pd.notna(x)) for x in put_aside_df.risk_type]\n",
    "\n",
    "    return evaluate_model(model, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e31e5-58ba-4a1e-9bcd-f6f99cfe742d",
   "metadata": {},
   "source": [
    "### Evaluate original labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a30f8-4a0b-4fd4-87a1-e5b58635c6bb",
   "metadata": {},
   "source": [
    "Evaluates the results of using the original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73984d3-90fa-4000-8e8e-6cda7671025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains and evaluates a model on the unfiltered data\n",
    "unfiltered_spanish_classification_report_ = check_results(spanish_df, spanish_put_aside_df, language='Spanish')\n",
    "unfiltered_portuguese_classification_report_ = check_results(portuguese_df, portuguese_put_aside_df, language='Portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ff466-02b4-42c2-9d4d-8daee232ce9b",
   "metadata": {},
   "source": [
    "### Evaluate improved labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126d221-5868-456e-ac19-b44f02998f69",
   "metadata": {},
   "source": [
    "Evaluates the results of using the improved labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c02ed1-4cf2-4851-aa3a-5ec85cc83660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains and evaluates a model on the filtered data\n",
    "filtered_spanish_classification_report_ = check_results(false_positives_filtered_spanish_df, spanish_put_aside_df, language='Spanish')\n",
    "filtered_portuguese_classification_report_ = check_results(false_positives_filtered_portuguese_df, portuguese_put_aside_df, language='Portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a000c-a525-4bf6-a3b0-4d260df1befb",
   "metadata": {},
   "source": [
    "## Repeat false negative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c771382-2c0b-4443-b996-8de07cd2f247",
   "metadata": {},
   "source": [
    "Given that the process above improved the model, it stands to reason that repeating the false negative filtering process with predictions based on the newly refined dataset could improve the model even further. The results below show that although the overall accuracy for both models declined (likely because we are dropping badly needed data), the most important metric for this project (risk headlines recall) went up in both datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afb43e-9984-4efe-a429-2edaa271d5e0",
   "metadata": {},
   "source": [
    "### Generate new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284b06d-aa56-4f12-94a9-367e6e1401e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resets the indices\n",
    "false_positives_filtered_spanish_df.reset_index(drop=True, inplace=True)\n",
    "false_positives_filtered_portuguese_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# creates additional dataframes with new predictions based on a model trained on the newly filtered dataframe\n",
    "spanish_df_3, spanish_df_4 = return_headline_preds(false_positives_filtered_spanish_df, 'Spanish')\n",
    "portuguese_df_3, portuguese_df_4 = return_headline_preds(false_positives_filtered_portuguese_df, 'Portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c6628-8031-4e03-962d-d0d12f6f0a56",
   "metadata": {},
   "source": [
    "### Find new false negatives threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62d713-ef4e-4038-8fd6-348af14f8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function shows the non-risk labelled headlines ordered\n",
    "# from the lowest to highest probability score. An ml practitioner \n",
    "# can use this to find the appropriate threshold for which \n",
    "# there are no longer many false negatives in the data...\n",
    "new_spanish_percent = view_nonrisk_highest_rows(spanish_df_4, 7001, 7011)\n",
    "new_portuguese_percent = view_nonrisk_highest_rows(portuguese_df_4, 1681, 1691)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929534e-1f22-43eb-be85-b9f298f672c1",
   "metadata": {},
   "source": [
    "### Drop headlines and evaluate new results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3d9ce-c862-4330-9df9-02dcf4a714a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new filtered dfs with fewer non-risk headlines\n",
    "new_filtered_spanish_df = create_filtered_df(spanish_df_3, spanish_df_4, new_spanish_percent)\n",
    "new_filtered_portuguese_df = create_filtered_df(portuguese_df_3, portuguese_df_4, new_portuguese_percent)\n",
    "\n",
    "# evaluates the results\n",
    "filtered_spanish_classification_report_ = check_results(new_filtered_spanish_df, spanish_put_aside_df, language='Spanish')\n",
    "filtered_portuguese_classification_report_ = check_results(new_filtered_portuguese_df, portuguese_put_aside_df, language='Portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c148d4-d5d1-419e-a7ca-d1dfee83bb30",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33aacf-3edf-42b6-8f29-6bd31ee67dcd",
   "metadata": {},
   "source": [
    "The results show a significant improvement for risk headline recall for both langugaes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b879b2-bbf1-411f-9a3f-d6564923d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# data\n",
    "base_model_spanish = [\n",
    "    unfiltered_spanish_classification_report_['accuracy'],\n",
    "    unfiltered_spanish_classification_report_['1']['precision'],\n",
    "    unfiltered_spanish_classification_report_['1']['recall']\n",
    "]\n",
    "new_model_spanish = [\n",
    "    filtered_spanish_classification_report_['accuracy'],\n",
    "    filtered_spanish_classification_report_['1']['precision'],\n",
    "    filtered_spanish_classification_report_['1']['recall']\n",
    "]\n",
    "base_model_portuguese = [\n",
    "    unfiltered_portuguese_classification_report_['accuracy'],\n",
    "    unfiltered_portuguese_classification_report_['1']['precision'],\n",
    "    unfiltered_portuguese_classification_report_['1']['recall']\n",
    "]\n",
    "new_model_portuguese = [\n",
    "    filtered_portuguese_classification_report_['accuracy'],\n",
    "    filtered_portuguese_classification_report_['1']['precision'],\n",
    "    filtered_portuguese_classification_report_['1']['recall']\n",
    "]\n",
    "\n",
    "# labels for the statistics\n",
    "labels = ['Overall Accuracy', 'Risk Headline Precision', 'Risk Headline Recall']\n",
    "colors = ['tab:blue', 'tab:red', 'tab:green']\n",
    "\n",
    "# create subplots for Spanish\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# plot baseline model stats for Spanish\n",
    "bars = axs[0].bar(labels, base_model_spanish, color=colors)\n",
    "axs[0].set_title('Original Labels')\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].set_ylabel('Score')\n",
    "\n",
    "# add numeric labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    axs[0].text(bar.get_x() + bar.get_width() / 2, yval + 0.01, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# plot new model stats for Spanish\n",
    "bars = axs[1].bar(labels, new_model_spanish, color=colors)\n",
    "axs[1].set_title('Improved Labels')\n",
    "axs[1].set_ylim(0, 1)\n",
    "\n",
    "# add numeric labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    axs[1].text(bar.get_x() + bar.get_width() / 2, yval + 0.01, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# add overall title for Spanish\n",
    "fig.suptitle('Spanish', fontsize=18)\n",
    "\n",
    "# adjust layout for better spacing\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# save image\n",
    "plt.savefig('../Images/improve_labels_spanish_metrics.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "# show the Spanish plot\n",
    "plt.show()\n",
    "\n",
    "# create subplots for Portuguese\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# plot baseline model stats for Portuguese\n",
    "bars = axs[0].bar(labels, base_model_portuguese, color=colors)\n",
    "axs[0].set_title('Original Labels')\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].set_ylabel('Score')\n",
    "\n",
    "# add numeric labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    axs[0].text(bar.get_x() + bar.get_width() / 2, yval + 0.01, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# plot new model stats for Portuguese\n",
    "bars = axs[1].bar(labels, new_model_portuguese, color=colors)\n",
    "axs[1].set_title('Improved Labels')\n",
    "axs[1].set_ylim(0, 1)\n",
    "\n",
    "# add numeric labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    axs[1].text(bar.get_x() + bar.get_width() / 2, yval + 0.01, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# add overall title for Portuguese\n",
    "fig.suptitle('Portuguese', fontsize=18, y=1)\n",
    "\n",
    "# adjust layout for better spacing\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# save image\n",
    "plt.savefig('../Images/improve_labels_portuguese_metrics.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "# show the Portuguese plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0e2dc-cd3e-4a9c-b3ec-fdfa04b693b6",
   "metadata": {},
   "source": [
    "## Save dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546fb10f-79cf-4f2d-a7c5-85c922d09976",
   "metadata": {},
   "source": [
    "Finally, the refined dataframes are saved as CSV files for further use in additional notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d1052-b5e0-42a5-8bb9-5106912d5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put aside data (for evaluation in other notebooks)\n",
    "spanish_put_aside_df.to_csv('../Data/spanish_put_aside_df.csv', index=False)\n",
    "portuguese_put_aside_df.to_csv('../Data/portuguese_put_aside_df.csv', index=False)\n",
    "\n",
    "# filtered dataframes (for use in further training)\n",
    "new_filtered_spanish_df.to_csv('../Data/spanish_df.csv', index=False)\n",
    "new_filtered_portuguese_df.to_csv('../Data/portuguese_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
