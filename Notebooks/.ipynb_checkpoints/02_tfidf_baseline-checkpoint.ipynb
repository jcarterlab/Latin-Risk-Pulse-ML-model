{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f2e3f2-1fe9-4a65-a368-fad8d3b15fbe",
   "metadata": {},
   "source": [
    "# 02) TF–IDF baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7572cae-82a3-4384-af17-0f51a933b62f",
   "metadata": {},
   "source": [
    "This notebook creates a baseline model using TF-IDF and logistic regression. A regression model is used to allow for the altering of the risk headline classification threshold. The primary business goal of this project is to create a model with a high recall. Although the overall accuracy for the Spanish and Portuguese models isn't that bad for a baseline model (see below), the recall for both of them in terms of risk headlines (1) is poor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e4bd5-9976-443f-88a3-75e7f35a2327",
   "metadata": {},
   "source": [
    "## Read-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28dc3b6b-8793-4bcc-ab8b-46b25b098204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.7K Spanish headlines\n",
      "12.7K Portuguese headlines\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read-in data\n",
    "df = pd.read_csv('../Data/original_headlines.csv', encoding='utf-8')\n",
    "\n",
    "# include only spanish \n",
    "spanish_df = df[df.country.isin(['Argentina', 'Colombia', 'Mexico'])].reset_index(drop=True)\n",
    "print(str(round(len(spanish_df)/1000, 1)) + 'K Spanish headlines')\n",
    "\n",
    "# include only portuguese \n",
    "portuguese_df = df[df.country == 'Brazil'].reset_index(drop=True)\n",
    "print(str(round(len(portuguese_df)/1000, 1)) + 'K Portuguese headlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12835759-47b7-460a-affa-68e64912997e",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89cd0bd6-672e-417d-8b64-a3bf20a6a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df):\n",
    "    X = df.headline\n",
    "    y = [int(pd.notna(x)) for x in df.risk_type]\n",
    "    return train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18789f-799e-42e8-a95c-ef6ae1d4942e",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2459bb-33d6-4236-95cd-aff59ea24152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jack-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text, language='english'):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + '¡¿'))\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e072d87-e2ba-4f05-9109-eef56a333069",
   "metadata": {},
   "source": [
    "## Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d6e372-824c-4980-af07-829743fd50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def vectorize_data(X_train, X_test=None, train_only=False):\n",
    "    if train_only==True:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        return X_train_tfidf\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = vectorizer.transform(X_test)\n",
    "        return X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c6382-0792-47d6-bf45-8b9d7b9112a8",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b4f28c-3537-4c9f-8935-76513ae92d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def fit_model(X_train_tfidf, y_train):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f80210-029d-4c9c-b363-0ee8bb194cf1",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deffe480-c789-4543-bb05-95cab456c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test_tfidf, y_test):\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    y_pred_prob = model.predict_proba(X_test_tfidf)[:, 1] \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94859175-5bfc-4b60-bbdc-2e870695880f",
   "metadata": {},
   "source": [
    "## Compare languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4813a4-f716-4b27-8185-9674a9604902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Spanish ***\n",
      "\n",
      "Accuracy: 0.9238150813719769\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     13559\n",
      "           1       0.86      0.44      0.58      1864\n",
      "\n",
      "    accuracy                           0.92     15423\n",
      "   macro avg       0.90      0.72      0.77     15423\n",
      "weighted avg       0.92      0.92      0.91     15423\n",
      "\n",
      "\n",
      "\n",
      "*** Portuguese ***\n",
      "\n",
      "Accuracy: 0.8458149779735683\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91      2463\n",
      "           1       0.82      0.40      0.54       715\n",
      "\n",
      "    accuracy                           0.85      3178\n",
      "   macro avg       0.83      0.69      0.72      3178\n",
      "weighted avg       0.84      0.85      0.82      3178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "languages = ['spanish', 'portuguese']\n",
    "\n",
    "def clean_train_evaluate(language):\n",
    "    df = eval(language + '_df')\n",
    "    df['headline'] = df['headline'].apply(clean_text, language=language)\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "    X_train_tfidf, X_test_tfidf = vectorize_data(X_train, X_test)\n",
    "    model = fit_model(X_train_tfidf, y_train)\n",
    "    evaluate_model(model, X_test_tfidf, y_test)\n",
    "\n",
    "for language in languages:\n",
    "    print()\n",
    "    print('*** ' + language.title() + ' ***')\n",
    "    print()\n",
    "    clean_train_evaluate(language)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd0a3b-efd3-4587-932d-38d480f6417c",
   "metadata": {},
   "source": [
    "## Test headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa76aeb-b3f4-4a38-b71d-60d9049d4f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05605419570785658"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following headline is deemed a risk headline that this model fails to predict...\n",
    "test_headline = 'Inversiones en sistema eléctrico, insuficientes para satisfacer la creciente demanda: IMCO'\n",
    "\n",
    "df = spanish_df\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "X_train_tfidf, X_test_tfidf = vectorize_data(X_train, X_test)\n",
    "model = fit_model(X_train_tfidf, y_train)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(X_train)\n",
    "cleaned_text = list(clean_text(test_headline, language='spanish'))\n",
    "test_vector = vectorizer.transform(cleaned_text)\n",
    "\n",
    "y_pred = model.predict(test_vector)\n",
    "y_pred_prob = model.predict_proba(test_vector)[:, 1] \n",
    "np.mean(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a057d8-4fa5-4dc6-8fa3-153b59ede59e",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438df0a3-1293-45d3-a565-7985a5259cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = '../Models/tfidf_baseline.pkl'\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
