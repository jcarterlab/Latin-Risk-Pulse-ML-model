{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f2e3f2-1fe9-4a65-a368-fad8d3b15fbe",
   "metadata": {},
   "source": [
    "# 02) TF–IDF baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7572cae-82a3-4384-af17-0f51a933b62f",
   "metadata": {},
   "source": [
    "This notebook creates a baseline model using TF-IDF and logistic regression. A regression model is used to allow for dynamic altering of the risk headline classification threshold in another program. The primary business goal of this project is to create a model with a high risk headline recall. Although the overall accuracy for the Spanish and Portuguese models isn't too bad for a baseline model, the recall for both of them in terms of risk headlines is poor, likely due to the presence of mislabelled data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e4bd5-9976-443f-88a3-75e7f35a2327",
   "metadata": {},
   "source": [
    "## Read-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28dc3b6b-8793-4bcc-ab8b-46b25b098204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.8K Total headlines\n",
      "69.3K Spanish headlines\n",
      "13.9K Portuguese headlines\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read-in data\n",
    "df = pd.read_csv('../Data/original_headlines.csv', encoding='utf-8')\n",
    "print(str(round(len(df)/1000, 1)) + 'K Total headlines')\n",
    "\n",
    "# include only spanish \n",
    "spanish_df = df[df.country.isin(['Argentina', 'Colombia', 'Mexico'])].reset_index(drop=True)\n",
    "print(str(round(len(spanish_df)/1000, 1)) + 'K Spanish headlines')\n",
    "\n",
    "# include only portuguese \n",
    "portuguese_df = df[df.country == 'Brazil'].reset_index(drop=True)\n",
    "print(str(round(len(portuguese_df)/1000, 1)) + 'K Portuguese headlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ffca0-2d2e-4c6c-8cbf-ffac56df9711",
   "metadata": {},
   "source": [
    "## Remove duplicates & thumbnails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc179a53-d93c-4b44-9292-1c7570f915ce",
   "metadata": {},
   "source": [
    "Headlines containing the word thumbnail are normally videos which cannot be scraped. Many of these with a similar format in the non-risk headlines data add little value in terms of variety and therefore are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f08e90-77d3-4c04-a780-12786c1510d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "spanish_df.drop_duplicates(subset='headline', inplace=True)\n",
    "portuguese_df.drop_duplicates(subset='headline', inplace=True)\n",
    "\n",
    "# remove thumbnails\n",
    "spanish_df = spanish_df[~spanish_df['headline'].str.lower().str.contains('thumbnail', na=False)]\n",
    "portuguese_df = portuguese_df[~portuguese_df['headline'].str.lower().str.contains('thumbnail', na=False)]\n",
    "\n",
    "# removes english headlines from the spanish dataset\n",
    "spanish_df = spanish_df.loc[~spanish_df.website.isin(['Colombia Reports'])]\n",
    "\n",
    "# reset index\n",
    "spanish_df.reset_index(drop=True, inplace=True)\n",
    "portuguese_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18789f-799e-42e8-a95c-ef6ae1d4942e",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4c5f7-f773-40bf-aa74-df536a170c72",
   "metadata": {},
   "source": [
    "The text is subjected to common cleaning techniques to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2459bb-33d6-4236-95cd-aff59ea24152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jack-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# common text cleaning techniques\n",
    "def clean_text(text, language='Spanish'):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + '¡¿'))\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c6382-0792-47d6-bf45-8b9d7b9112a8",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbdd24-0e54-495d-9284-ce93fb74c958",
   "metadata": {},
   "source": [
    "A model is fit using TF-IDF vectors and logistic regression. A regression model is used to obtain probabilities so that the classification threshold can be easily varied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b4f28c-3537-4c9f-8935-76513ae92d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# vectorizes data\n",
    "def vectorize_data(X_train, X_test=None, train_only=False):\n",
    "    if train_only==True:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        return X_train_tfidf\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = vectorizer.transform(X_test)\n",
    "        return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "# fits a model \n",
    "def fit_model(X_train_tfidf, y_train):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3dadd1-62ce-46a7-93a2-40720d2c9988",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be489b02-16d4-4fcc-a53b-0bf076cd3bae",
   "metadata": {},
   "source": [
    "Creates a train test split for a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43604914-30ec-470d-9788-062bb69ab80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# returns a train test split\n",
    "def split_data(df):\n",
    "    X = df.headline\n",
    "    y = [int(pd.notna(x)) for x in df.risk_type]\n",
    "    return train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f80210-029d-4c9c-b363-0ee8bb194cf1",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455b1f5-61f2-4ef6-9e1e-551ec5698a02",
   "metadata": {},
   "source": [
    "Prints the accuracy and classification report for a given model on a given set of headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deffe480-c789-4543-bb05-95cab456c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# evaluates a model by printing the accuracy and classification report\n",
    "def evaluate_model(model, X_test_tfidf, y_test):\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    y_pred_prob = model.predict_proba(X_test_tfidf)[:, 1] \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94859175-5bfc-4b60-bbdc-2e870695880f",
   "metadata": {},
   "source": [
    "## Compare languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333daa9e-04b7-4493-84e0-58f15f3c25b3",
   "metadata": {},
   "source": [
    "Compares the the performance of both languages. The results indicate that most important metric of this project from a business perspective, risk headlines recall, is very low for both languages (0.44 and 0.38), possibly due to the presence of mislabelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4813a4-f716-4b27-8185-9674a9604902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Spanish ***\n",
      "\n",
      "Accuracy: 0.9139059840251408\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     13235\n",
      "           1       0.84      0.44      0.58      2039\n",
      "\n",
      "    accuracy                           0.91     15274\n",
      "   macro avg       0.88      0.71      0.76     15274\n",
      "weighted avg       0.91      0.91      0.90     15274\n",
      "\n",
      "\n",
      "\n",
      "*** Portuguese ***\n",
      "\n",
      "Accuracy: 0.8422484134179511\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      2558\n",
      "           1       0.83      0.38      0.52       751\n",
      "\n",
      "    accuracy                           0.84      3309\n",
      "   macro avg       0.84      0.68      0.71      3309\n",
      "weighted avg       0.84      0.84      0.82      3309\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "languages = ['spanish', 'portuguese']\n",
    "\n",
    "# cleans the headlines vectorizes the text and evaluates the model\n",
    "def clean_train_evaluate(language):\n",
    "    df = eval(language + '_df')\n",
    "    df['headline'] = df['headline'].apply(clean_text, language=language)\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "    X_train_tfidf, X_test_tfidf = vectorize_data(X_train, X_test)\n",
    "    model = fit_model(X_train_tfidf, y_train)\n",
    "    evaluate_model(model, X_test_tfidf, y_test)\n",
    "\n",
    "for language in languages:\n",
    "    print()\n",
    "    print('*** ' + language.title() + ' ***')\n",
    "    print()\n",
    "    clean_train_evaluate(language)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd0a3b-efd3-4587-932d-38d480f6417c",
   "metadata": {},
   "source": [
    "## Test headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e051252-08ae-4b92-99bb-6a107a62c42b",
   "metadata": {},
   "source": [
    "A new headline deemed by Gemini as a potential business risk according to our criteria returns a very low probability from the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa76aeb-b3f4-4a38-b71d-60d9049d4f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05588372402500921"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following headline is deemed a risk headline that this model fails to predict...\n",
    "test_headline = 'Inversiones en sistema eléctrico, insuficientes para satisfacer la creciente demanda: IMCO'\n",
    "\n",
    "df = spanish_df\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "X_train_tfidf, X_test_tfidf = vectorize_data(X_train, X_test)\n",
    "model = fit_model(X_train_tfidf, y_train)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(X_train)\n",
    "cleaned_text = list(clean_text(test_headline, language='spanish'))\n",
    "test_vector = vectorizer.transform(cleaned_text)\n",
    "\n",
    "y_pred = model.predict(test_vector)\n",
    "y_pred_prob = model.predict_proba(test_vector)[:, 1] \n",
    "np.mean(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a057d8-4fa5-4dc6-8fa3-153b59ede59e",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e1b96-50e4-4191-bb75-ce42c1e7fcf6",
   "metadata": {},
   "source": [
    "The model is saved for comparison purposes later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438df0a3-1293-45d3-a565-7985a5259cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = '../Models/tfidf_baseline.pkl'\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
